#!/usr/bin/env python3
"""GitGuard - A tool to help maintain consistent git commit messages."""

import sys
import os
from pathlib import Path
from subprocess import check_output
import json
from typing import Dict, List, Optional, Set
import requests

# Try to import optional dependencies
try:
    from openai import AzureOpenAI

    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False


class Config:
    """Configuration handler with global and local settings."""

    DEFAULT_CONFIG = {
        "auto_mode": False,
        "use_ai": True,
        "ai_provider": "azure",  # Can be 'azure' or 'ollama'
        "azure_endpoint": "https://consensys-ai.openai.azure.com/",
        "azure_deployment": "gpt-4o",
        "azure_fallback_deployment": "gpt-35-turbo-16k",  # Fallback model
        "azure_api_version": "2024-02-15-preview",
        "azure_fallback_api_version": "2024-02-15-preview",  # Fallback API version
        "ollama_host": "http://localhost:11434",
        "ollama_model": "codellama",
        "debug": True,
    }

    def __init__(self):
        self._config = self.DEFAULT_CONFIG.copy()
        self._load_configurations()

    def _load_json_file(self, path: Path) -> Dict:
        try:
            if path.exists():
                return json.loads(path.read_text())
        except Exception as e:
            if self._config.get("debug"):
                print(f"‚ö†Ô∏è  Error loading config from {path}: {e}")
        return {}

    def _load_configurations(self):
        # 1. Global configuration
        global_config = self._load_json_file(Path.home() / ".gitguard" / "config.json")
        self._config.update(global_config)

        # 2. Local configuration
        try:
            git_root = Path(
                check_output(["git", "rev-parse", "--show-toplevel"], text=True).strip()
            )
            local_config = self._load_json_file(git_root / ".gitguard" / "config.json")
            self._config.update(local_config)
        except Exception:
            pass

        # 3. Environment variables
        env_mappings = {
            "GITGUARD_AUTO": ("auto_mode", lambda x: x.lower() in ("1", "true", "yes")),
            "GITGUARD_USE_AI": ("use_ai", lambda x: x.lower() in ("1", "true", "yes")),
            "AZURE_OPENAI_ENDPOINT": ("azure_endpoint", str),
            "AZURE_OPENAI_DEPLOYMENT": ("azure_deployment", str),
            "AZURE_OPENAI_API_VERSION": ("azure_api_version", str),
            "GITGUARD_DEBUG": ("debug", lambda x: x.lower() in ("1", "true", "yes")),
        }

        for env_var, (config_key, transform) in env_mappings.items():
            if (value := os.environ.get(env_var)) is not None:
                self._config[config_key] = transform(value)

        if self._config.get("debug"):
            print("\nüîß Active configuration:", json.dumps(self._config, indent=2))

    def get(self, key: str, default=None):
        return self._config.get(key, default)


class OllamaClient:
    """Client for interacting with Ollama API."""

    def __init__(self, host: str, model: str):
        self.host = host.rstrip("/")
        self.model = model

    def generate(
        self, system_prompt: str, user_prompt: str
    ) -> Optional[List[Dict[str, str]]]:
        """Generate commit message suggestions using Ollama."""
        try:
            response = requests.post(
                f"{self.host}/api/generate",
                json={
                    "model": self.model,
                    "prompt": f"{system_prompt}\n\n{user_prompt}",
                    "stream": False,
                },
            )
            response.raise_for_status()

            result = response.json()
            response_text = result.get("response", "")

            try:
                # Find JSON object in the response
                start = response_text.find("{")
                end = response_text.rfind("}") + 1
                if start >= 0 and end > start:
                    json_str = response_text[start:end]
                    suggestions = json.loads(json_str).get("suggestions", [])
                    return suggestions[:3]
            except json.JSONDecodeError:
                print("\n‚ö†Ô∏è  Failed to parse Ollama response as JSON")

            # Fallback: Create a single suggestion from the raw response
            return [
                {
                    "message": response_text.split("\n")[0],
                    "explanation": "Generated by Ollama",
                    "type": "feat",
                    "scope": "default",
                    "description": response_text,
                }
            ]

        except Exception as e:
            print(f"\n‚ö†Ô∏è  Ollama API error: {str(e)}")
            return None


def get_azure_suggestions(
    client: AzureOpenAI,
    config: Config,
    system_prompt: str,
    user_prompt: str,
    deployment: str,
    api_version: str
) -> Optional[List[Dict[str, str]]]:
    """Get suggestions from Azure OpenAI with specific deployment and API version."""
    try:
        # Update client with specific API version
        client.api_version = api_version
        
        response = client.chat.completions.create(
            model=deployment,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.9,
            max_tokens=1500,
            n=3,
            response_format={"type": "json_object"},
        )

        all_suggestions = []
        for choice in response.choices:
            result = json.loads(choice.message.content)
            all_suggestions.extend(result.get("suggestions", []))

        return all_suggestions[:3]

    except Exception as e:
        if config.get("debug"):
            print(f"\n‚ö†Ô∏è  Azure OpenAI error with {deployment} (API version {api_version}): {str(e)}")
        raise  # Re-raise the exception to handle it in the calling function


def get_ai_suggestion(prompt: str, original_message: str) -> Optional[List[Dict[str, str]]]:
    """Get structured commit message suggestions from configured AI provider."""
    config = Config()
    
    if config.get("debug"):
        print("\nüîß Active configuration:", json.dumps(config._config, indent=2))

    system_prompt = """You are a helpful git commit message assistant. 
    Provide exactly 3 different conventional commit message suggestions, each with a unique approach.
    Return your response in the following JSON format:
    {
        "suggestions": [
            {
                "message": "type(scope): description",
                "explanation": "Brief explanation of why this format was chosen",
                "type": "commit type used",
                "scope": "scope used",
                "description": "main message"
            }
        ]
    }
    Ensure each suggestion has a different focus or perspective."""

    # Try Ollama if configured
    if config.get("ai_provider") == "ollama":
        client = OllamaClient(
            host=config.get("ollama_host"),
            model=config.get("ollama_model")
        )
        suggestions = client.generate(system_prompt, prompt)
        if suggestions:
            return suggestions

    # Try Azure OpenAI if available
    if HAS_OPENAI:
        api_key = config.get("azure_api_key") or os.getenv("AZURE_OPENAI_API_KEY")
        if not api_key:
            print("\n‚ö†Ô∏è  No Azure OpenAI API key found in config or environment")
            return None

        # Create new client for each attempt to ensure clean state
        def create_client(api_version: str) -> AzureOpenAI:
            return AzureOpenAI(
                api_key=api_key,
                api_version=api_version,
                azure_endpoint=config.get("azure_endpoint"),
            )

        # Try primary model
        try:
            if config.get("debug"):
                print(f"\nüîß Using primary model: {config.get('azure_deployment')}")
                print(f"API Version: {config.get('azure_api_version')}")
                print(f"Endpoint: {config.get('azure_endpoint')}")
            
            client = create_client(config.get("azure_api_version"))
            suggestions = get_azure_suggestions(
                client,
                config,
                system_prompt,
                prompt,
                config.get("azure_deployment"),
                config.get("azure_api_version")
            )
            if suggestions:
                return suggestions

        except Exception as primary_error:
            # Try fallback model
            if config.get("azure_fallback_deployment"):
                try:
                    if config.get("debug"):
                        print(f"\nüîÑ Trying fallback model: {config.get('azure_fallback_deployment')}")
                        print(f"Fallback API Version: {config.get('azure_fallback_api_version', config.get('azure_api_version'))}")
                    
                    fallback_api_version = config.get("azure_fallback_api_version", config.get("azure_api_version"))
                    client = create_client(fallback_api_version)
                    suggestions = get_azure_suggestions(
                        client,
                        config,
                        system_prompt,
                        prompt,
                        config.get("azure_fallback_deployment"),
                        fallback_api_version
                    )
                    if suggestions:
                        return suggestions
                    
                except Exception as fallback_error:
                    if config.get("debug"):
                        print(f"\n‚ö†Ô∏è  Fallback model failed: {str(fallback_error)}")
            else:
                if config.get("debug"):
                    print("\n‚ö†Ô∏è  No fallback model configured")
    
    return None


def detect_change_types(files: List[str]) -> Set[str]:
    """Detect change types based on files modified."""
    types = set()

    for file in files:
        file_lower = file.lower()
        name = Path(file).name.lower()

        if any(pattern in file_lower for pattern in [".test.", ".spec.", "/tests/"]):
            types.add("test")
        elif any(pattern in file_lower for pattern in [".md", "readme", "docs/"]):
            types.add("docs")
        elif any(pattern in file_lower for pattern in [".css", ".scss", ".styled."]):
            types.add("style")
        elif any(
            pattern in name for pattern in ["package.json", ".config.", "tsconfig"]
        ):
            types.add("chore")
        elif any(word in file_lower for word in ["fix", "bug", "patch"]):
            types.add("fix")

    if not types:
        types.add("feat")

    return types


def get_package_json_name(package_path: Path) -> Optional[str]:
    """Get package name from package.json if it exists."""
    try:
        pkg_json_path = Path.cwd() / package_path / "package.json"
        if pkg_json_path.exists():
            return json.loads(pkg_json_path.read_text()).get("name")
    except:
        return None
    return None


def get_changed_packages() -> List[Dict]:
    """Get all packages with changes in the current commit."""
    changed_files = check_output(["git", "diff", "--cached", "--name-only"])
    changed_files = changed_files.decode("utf-8").strip().split("\n")

    packages = {}
    for file in changed_files:
        if not file:
            continue

        if file.startswith("packages/"):
            parts = file.split("/")
            if len(parts) > 1:
                pkg_path = f"packages/{parts[1]}"
                if pkg_path not in packages:
                    packages[pkg_path] = []
                packages[pkg_path].append(file)
        else:
            if "root" not in packages:
                packages["root"] = []
            packages["root"].append(file)

    results = []
    for pkg_path, files in packages.items():
        if pkg_path == "root":
            scope = name = "root"
        else:
            pkg_name = get_package_json_name(Path(pkg_path))
            if pkg_name:
                name = pkg_name
                scope = pkg_name.split("/")[-1]
            else:
                name = scope = pkg_path.split("/")[-1]

        results.append(
            {
                "name": name,
                "scope": scope,
                "files": files,
                "types": detect_change_types(files),
            }
        )

    return results


def format_commit_message(
    original_msg: str, package: Dict, commit_type: Optional[str] = None
) -> str:
    """Format commit message for a single package."""
    if ":" in original_msg:
        type_part, msg = original_msg.split(":", 1)
        msg = msg.strip()
        if "(" in type_part and ")" in type_part:
            commit_type = type_part.split("(")[0]
        else:
            commit_type = type_part
    else:
        msg = original_msg
        if not commit_type:
            commit_type = next(iter(package["types"]))

    return f"{commit_type}({package['scope']}): {msg}"


def generate_ai_prompt(packages: List[Dict], original_msg: str) -> str:
    """Generate a detailed prompt for AI assistance."""
    try:
        diff = check_output(["git", "diff", "--cached"]).decode("utf-8")
    except:
        diff = "Failed to get diff"

    prompt = f"""Please suggest a git commit message following conventional commits format.

Original message: "{original_msg}"

Changed packages:
{'-' * 40}"""

    for pkg in packages:
        prompt += f"""

üì¶ Package: {pkg['name']}
Detected change types: {', '.join(pkg['types'])}
Files changed:
{chr(10).join(f'- {file}' for file in pkg['files'])}"""

    prompt += f"""
{'-' * 40}

Git diff:
```diff
{diff}
```

Please provide a single commit message that:
1. Follows the format: type(scope): description
2. Uses the most significant package as scope
3. Lists other affected packages if any
4. Includes brief bullet points for significant changes

Use one of: feat|fix|docs|style|refactor|perf|test|chore
Keep the description clear and concise"""

    return prompt


def prompt_user(question: str) -> bool:
    """Prompt user for yes/no question using /dev/tty."""
    try:
        with open("/dev/tty", "r", encoding="utf-8") as tty:
            print(f"{question} [Y/n]", end=" ", flush=True)
            response = tty.readline().strip().lower()
            return response == "" or response != "n"
    except Exception as e:
        print(f"Warning: Could not get user input: {str(e)}")
        return True


def display_suggestions(suggestions: List[Dict[str, str]]) -> Optional[str]:
    """Display suggestions and get user choice, defaults to the first suggestion on EOF."""
    print("\n‚ú® AI Suggestions:")

    for i, suggestion in enumerate(suggestions, 1):
        print(f"\n{i}. {'=' * 48}")
        print(f"Message: {suggestion['message']}")
        print(f"Type: {suggestion['type']}")
        print(f"Scope: {suggestion['scope']}")
        print(f"Explanation: {suggestion['explanation']}")
        print("=" * 50)

    try:
        with open("/dev/tty", "r", encoding="utf-8") as tty:
            while True:
                print(
                    "\nChoose suggestion (1-3) or press Enter to skip: ",
                    end="",
                    flush=True,
                )
                choice = tty.readline().strip()
                if not choice:
                    return None
                if choice in ("1", "2", "3"):
                    return suggestions[int(choice) - 1]["message"]
                print("Please enter 1, 2, 3 or press Enter to skip")
    except EOFError:
        print("\n‚ö†Ô∏è  Input not available. Defaulting to first suggestion.")
        return suggestions[0]["message"] if suggestions else None


def get_main_package(packages: List[Dict]) -> Optional[Dict]:
    """Get the package with the most changes."""
    if not packages:
        return {"name": "default", "scope": "default", "files": [], "types": {"feat"}}

    # Sort packages by number of files changed
    sorted_packages = sorted(packages, key=lambda x: len(x["files"]), reverse=True)
    return sorted_packages[0]


def main() -> None:
    """Main function to process git commit messages."""
    try:
        config = Config()

        commit_msg_file = sys.argv[1]
        with open(commit_msg_file, "r", encoding="utf-8") as f:
            original_msg = f.read().strip()

        if original_msg.startswith("Merge"):
            sys.exit(0)

        packages = get_changed_packages()
        if not packages:
            sys.exit(0)

        print("\nüîç Analyzing changes...")
        print("Original message:", original_msg)

        # Handle multiple packages first
        if len(packages) > 1:
            print("\nüì¶ Changes in multiple packages:")
            for pkg in packages:
                print(f"‚Ä¢ {pkg['name']} ({', '.join(pkg['types'])})")
                for file in pkg["files"]:
                    print(f"  - {file}")
            print("\n‚ö†Ô∏è  Consider splitting this commit for better readability!")

        # AI suggestion flow - only if user wants it
        if prompt_user("\nWould you like AI suggestions?"):
            print("\nü§ñ Getting AI suggestions...")
            prompt = generate_ai_prompt(packages, original_msg)
            suggestions = get_ai_suggestion(prompt, original_msg)

            if suggestions:
                chosen_message = display_suggestions(suggestions)
                if chosen_message:
                    with open(commit_msg_file, "w", encoding="utf-8") as f:
                        f.write(chosen_message)
                    print("‚úÖ Commit message updated!\n")
                    return

        # Fallback to automatic formatting
        if len(packages) > 1:
            main_pkg = get_main_package(packages)  # Use the package with most changes
            main_type = next(iter(main_pkg["types"]))
            new_msg = format_commit_message(original_msg, main_pkg, main_type)
            new_msg += "\n\nAffected packages:\n" + "\n".join(
                f"- {p['name']}" for p in packages
            )
        else:
            pkg = packages[0]
            main_type = next(iter(pkg["types"]))
            new_msg = format_commit_message(original_msg, pkg, main_type)

        print(f"\n‚ú® Suggested message: {new_msg}")

        if prompt_user("\nUse suggested message?"):
            with open(commit_msg_file, "w", encoding="utf-8") as f:
                f.write(new_msg)
            print("‚úÖ Commit message updated!\n")

    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()
