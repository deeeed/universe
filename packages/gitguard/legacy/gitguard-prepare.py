#!/usr/bin/env python3
"""GitGuard - A tool to help maintain consistent git commit messages."""

import sys
import os
import requests
import re
import json
from pathlib import Path
from subprocess import check_output
from typing import Dict, List, Optional, Set, Any, Tuple
from collections import defaultdict
import subprocess


# Try to import optional dependencies / check
try:
    from openai import AzureOpenAI
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False

try:
    import tiktoken
    HAS_TIKTOKEN = True
except ImportError:
    HAS_TIKTOKEN = False

class Config:
    """Configuration handler with global and local settings."""
    DEFAULT_CONFIG = {
        "auto_mode": False,
        "use_ai": True,
        "ai_provider": "azure",  # Can be 'azure' or 'ollama'
        "azure_endpoint": "https://your-endpoint.openai.azure.com/",
        "azure_deployment": "gpt-4",
        "azure_api_version": "2024-05-13",
        "ollama_host": "http://localhost:11434",
        "ollama_model": "codellama",
        "debug": False,
    }

    def __init__(self):
        self._config = self.DEFAULT_CONFIG.copy()
        self._load_configurations()

    def _load_json_file(self, path: Path) -> Dict:
        try:
            if path.exists():
                return json.loads(path.read_text())
        except Exception as e:
            if self._config.get("debug"):
                print(f"⚠️  Error loading config from {path}: {e}")
        return {}

    def _load_configurations(self):
        # 1. Global configuration
        global_config = self._load_json_file(Path.home() / ".gitguard" / "config.json")
        self._config.update(global_config)

        # 2. Local configuration
        try:
            git_root = Path(check_output(["git", "rev-parse", "--show-toplevel"], text=True).strip())
            local_config = self._load_json_file(git_root / ".gitguard" / "config.json")
            self._config.update(local_config)
        except Exception:
            pass

        # 3. Environment variables
        env_mappings = {
            "GITGUARD_AUTO": ("auto_mode", lambda x: x.lower() in ("1", "true", "yes")),
            "GITGUARD_USE_AI": ("use_ai", lambda x: x.lower() in ("1", "true", "yes")),
            "AZURE_OPENAI_ENDPOINT": ("azure_endpoint", str),
            "AZURE_OPENAI_DEPLOYMENT": ("azure_deployment", str),
            "AZURE_OPENAI_API_VERSION": ("azure_api_version", str),
            "GITGUARD_DEBUG": ("debug", lambda x: x.lower() in ("1", "true", "yes")),
        }

        for env_var, (config_key, transform) in env_mappings.items():
            if (value := os.environ.get(env_var)) is not None:
                self._config[config_key] = transform(value)

        if self._config.get("debug"):
            print("\n🔧 Active configuration:", json.dumps(self._config, indent=2))

    def get(self, key: str, default=None):
        return self._config.get(key, default)

class OllamaClient:
    """Client for interacting with Ollama API."""
    def __init__(self, host: str, model: str):
        self.host = host.rstrip("/")
        self.model = model

    def generate(self, prompt: str, original_message: str) -> Optional[List[Dict[str, str]]]:
        """Generate commit message suggestions using Ollama."""
        try:
            response = requests.post(
                f"{self.host}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                },
            )
            response.raise_for_status()
            
            result = response.json()
            response_text = result.get("response", "")
            
            try:
                # Find JSON object in the response
                start = response_text.find("{")
                end = response_text.rfind("}") + 1
                if start >= 0 and end > start:
                    json_str = response_text[start:end]
                    suggestions = json.loads(json_str).get("suggestions", [])
                    return suggestions[:3]
            except json.JSONDecodeError:
                print("\n⚠️  Failed to parse Ollama response as JSON")
            
            # Fallback: Create a single suggestion from the raw response
            return [{
                "message": response_text.split("\n")[0],
                "explanation": "Generated by Ollama",
                "type": "feat",
                "scope": "default",
                "description": response_text,
            }]
            
        except Exception as e:
            print(f"\n⚠️  Ollama API error: {str(e)}")
            return None

def debug_log(message: str, title: str = "Debug", separator: bool = True) -> None:
    """Print debug messages in a clearly visible format."""
    if not Config().get("debug"):
        return
        
    print("\n" + "═" * 80)
    print(f"🔍 {title.upper()}")
    print("═" * 80)
    print(message)
    if separator:
        print("═" * 80)

def calculate_commit_complexity(packages: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Calculate commit complexity metrics to determine if structured format is needed."""
    complexity = {
        "score": 0,
        "reasons": [],
        "needs_structure": False
    }
    
    # 1. Multiple packages changes (most significant factor)
    if len(packages) > 1:
        complexity["score"] += 3
        complexity["reasons"].append("Changes span multiple packages")
    
    # 2. Number of files changed
    total_files = sum(len(pkg["files"]) for pkg in packages)
    if total_files > 3:
        complexity["score"] += min(total_files - 3, 5)  # Cap at 5 points
        complexity["reasons"].append(f"Large number of files changed ({total_files})")
    
    # 3. Mixed content types (e.g., code + tests + config)
    content_types = set()
    for pkg in packages:
        for file in pkg["files"]:
            if file.endswith(('.test.ts', '.test.js', '.spec.ts', '.spec.js')):
                content_types.add('test')
            elif file.endswith(('.json', '.yml', '.yaml', '.config.js')):
                content_types.add('config')
            elif file.endswith(('.css', '.scss', '.less')):
                content_types.add('styles')
            elif file.endswith(('.ts', '.js', '.tsx', '.jsx')):
                content_types.add('code')
            
    if len(content_types) > 2:
        complexity["score"] += 2
        complexity["reasons"].append("Multiple content types modified")
    
    # Determine if structured commit is needed (threshold = 5)
    complexity["needs_structure"] = complexity["score"] >= 5
    
    if Config().get("debug"):
        debug_log(
            f"Score: {complexity['score']}\nReasons:\n" + 
            "\n".join(f"- {reason}" for reason in complexity["reasons"]),
            "Complexity Analysis 📊"
        )
    
    return complexity

def group_files_by_type(files: List[str]) -> Dict[str, List[str]]:
    """Group files by their type for better readability."""
    groups = {
        "Tests": [],
        "Config": [],
        "Styles": [],
        "Source": []
    }
    
    for file in files:
        if file.endswith(('.test.ts', '.test.js', '.spec.ts', '.spec.js')):
            groups["Tests"].append(file)
        elif file.endswith(('.json', '.yml', '.yaml', '.config.js')):
            groups["Config"].append(file)
        elif file.endswith(('.css', '.scss', '.less')):
            groups["Styles"].append(file)
        else:
            groups["Source"].append(file)
    
    # Return only non-empty groups
    return {k: v for k, v in groups.items() if v}

def enhance_ai_prompt(packages: List[Dict], original_msg: str) -> str:
    """Generate detailed AI prompt based on commit complexity analysis."""
    complexity = calculate_commit_complexity(packages)
    is_mono = is_monorepo()
    
    try:
        diff = check_output(["git", "diff", "--cached"]).decode("utf-8")
    except:
        diff = "Failed to get diff"
    
    # Build comprehensive analysis for AI
    analysis = {
        "complexity_score": complexity["score"],
        "complexity_reasons": complexity["reasons"],
        "repository_type": "monorepo" if is_mono else "standard",
        "packages": []
    }
    
    for pkg in packages:
        files_by_type = group_files_by_type(pkg["files"])
        analysis["packages"].append({
            "name": pkg["name"],
            "scope": pkg["scope"],
            "files_by_type": files_by_type
        })

    prompt = f"""Analyze the following git changes and suggest a commit message.

Repository Type: {analysis['repository_type']}
Complexity Analysis:
- Score: {complexity['score']} (threshold for structured format: 5)
- Factors: {', '.join(complexity['reasons'])}

Changed Files:"""

    for pkg in analysis["packages"]:
        if is_mono:
            prompt += f"\n\n📦 {pkg['name']}" + (f" ({pkg['scope']})" if pkg['scope'] else "")
        else:
            prompt += f"\n\nDirectory: {pkg['name']}"
            
        for file_type, files in pkg["files_by_type"].items():
            prompt += f"\n{file_type}:"
            for file in files:
                prompt += f"\n  - {file}"

    prompt += f"""

Original message: "{original_msg}"

Git diff:
```diff
{diff}
```

Please provide 3 conventional commit suggestions in this JSON format:
{{
    "suggestions": [
        {{
            "message": "complete commit message",
            "explanation": "reasoning",
            "type": "commit type",
            "scope": "{'scope (required for monorepo)' if is_mono else 'scope (optional)'}",
            "description": "title description"
        }}
    ]
}}

{'Note: This is a monorepo, so package scope is required.' if is_mono else 'Note: This is a standard repository, so scope is optional.'}
"""

    return prompt

def count_tokens(text: str) -> int:
    """Count tokens using tiktoken if available, otherwise estimate."""
    if HAS_TIKTOKEN:
        try:
            # Use the appropriate model encoding
            encoding = tiktoken.encoding_for_model("gpt-4")
            token_count = len(encoding.encode(text))
            return token_count
        except Exception as e:
            debug_log(f"Tiktoken error: {str(e)}, falling back to estimation", "Warning ⚠️")
            return len(text) // 4
    else:
        debug_log(
            "Tiktoken not installed. For accurate token counting, install with:\n" +
            "pip install tiktoken",
            "Token Count Info ℹ️"
        )
        return len(text) // 4

def get_token_cost(token_count: int) -> str:
    """Calculate cost based on current GPT-4 pricing."""
    # Current GPT-4 Turbo pricing (as of 2024)
    COST_PER_1K_INPUT = 0.01
    COST_PER_1K_OUTPUT = 0.03
    
    # Estimate output tokens as ~25% of input
    estimated_output_tokens = token_count * 0.25
    
    input_cost = (token_count / 1000) * COST_PER_1K_INPUT
    output_cost = (estimated_output_tokens / 1000) * COST_PER_1K_OUTPUT
    total_cost = input_cost + output_cost
    
    return (
        f"Input tokens: {token_count:,}\n"
        f"Estimated output tokens: {int(estimated_output_tokens):,}\n"
        f"Estimated total cost: ${total_cost:.4f}\n"
        f"  - Input cost: ${input_cost:.4f}\n"
        f"  - Output cost: ${output_cost:.4f}"
    )

def get_ai_suggestion(prompt: str, original_message: str) -> Optional[List[Dict[str, str]]]:
    """Get structured commit message suggestions from configured AI provider."""
    config = Config()
    
    # Calculate and log token usage estimation
    token_count = count_tokens(prompt)
    debug_log(
        f"Estimated tokens: {token_count}\n"
        f"Estimated cost: ${(token_count / 1000 * 0.03):.4f} (GPT-4 rate)",
        "Token Usage 💰"
    )

    if config.get("debug"):
        debug_log(prompt, "AI Prompt")

    # Try Azure OpenAI if available
    if HAS_OPENAI and config.get("ai_provider") == "azure":
        api_key = config.get("azure_api_key") or os.getenv("AZURE_OPENAI_API_KEY")
        if not api_key:
            debug_log("No Azure OpenAI API key found in config or environment", "Warning ⚠️")
            return None

        try:
            client = AzureOpenAI(
                api_key=api_key,
                api_version=config.get("azure_api_version"),
                azure_endpoint=config.get("azure_endpoint"),
            )
            
            # Default suggestions template
            default_suggestions = [
                {
                    "message": original_message,
                    "explanation": "Original message preserved due to API error",
                    "type": "feat",
                    "scope": "default",
                    "description": original_message
                }
            ]
            
            # Try primary deployment (GPT-4) first
            try:
                debug_log(f"Attempting GPT-4 request to {config.get('azure_deployment')}", "Azure OpenAI 🤖")
                
                response = client.chat.completions.create(
                    model=config.get("azure_deployment"),
                    messages=[
                        {
                            "role": "system", 
                            "content": "You are a git commit message assistant. Generate 3 distinct conventional commit format suggestions in JSON format."
                        },
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7,
                    max_tokens=1500,
                    n=1,
                    response_format={"type": "json_object"},
                )

                result = json.loads(response.choices[0].message.content)
                suggestions = result.get("suggestions", [])
                
                if suggestions:
                    debug_log(
                        f"Received {len(suggestions)} suggestions\n" + 
                        json.dumps(suggestions, indent=2),
                        "GPT-4 Response ✨"
                    )
                    return suggestions[:3]  # Ensure we return up to 3 suggestions
                return default_suggestions

            except Exception as e:
                debug_log(f"Primary model error: {str(e)}", "Error ❌")
                
                # Try fallback deployment (GPT-3.5) with simplified response
                fallback_deployment = config.get("azure_fallback_deployment")
                if fallback_deployment:
                    try:
                        debug_log(f"Attempting fallback to {fallback_deployment}", "Fallback Model 🔄")
                        
                        response = client.chat.completions.create(
                            model=fallback_deployment,
                            messages=[
                                {"role": "system", "content": "You are a helpful git commit message assistant."},
                                {"role": "user", "content": prompt}
                            ],
                            temperature=0.7,
                            max_tokens=500,
                            n=1,
                        )
                        
                        message = response.choices[0].message.content.strip()
                        debug_log(message, "Fallback Response 📝")
                        
                        return [{
                            "message": message,
                            "explanation": "Generated using fallback model",
                            "type": "feat",
                            "scope": "default",
                            "description": message
                        }]
                    except Exception as fallback_error:
                        debug_log(f"Fallback model error: {str(fallback_error)}", "Error ❌")
                        return default_suggestions

        except Exception as e:
            debug_log(f"Azure OpenAI error: {str(e)}", "Error ❌")
            return default_suggestions

    # Fallback to Ollama if configured
    if config.get("ai_provider") == "ollama":
        debug_log("Attempting Ollama request", "Ollama 🤖")
        client = OllamaClient(
            host=config.get("ollama_host"),
            model=config.get("ollama_model")
        )
        return client.generate(prompt, original_message)

    return None

def create_commit_message(commit_info: Dict[str, Any], packages: List[Dict[str, Any]]) -> str:
    """Create appropriate commit message based on complexity."""
    description = commit_info['description']
    type_pattern = r'^(feat|fix|docs|style|refactor|test|chore|build|ci|perf|revert)(\([^)]+\))?:\s*'
    if re.match(type_pattern, description):
        description = re.sub(type_pattern, '', description)
        commit_info['description'] = description.strip()

    complexity = calculate_commit_complexity(packages)
    
    if Config().get("debug"):
        print("\n🔍 Commit Complexity Analysis:")
        print(f"Score: {complexity['score']}")
        print("Reasons:")
        for reason in complexity["reasons"]:
            print(f"- {reason}")
    
    # For simple commits
    if not complexity["needs_structure"]:
        # Only include scope if it exists (for monorepo) or is explicitly set
        if commit_info.get('scope'):
            return f"{commit_info['type']}({commit_info['scope']}): {commit_info['description']}"
        return f"{commit_info['type']}: {commit_info['description']}"
    
    # For complex commits
    return create_structured_commit(commit_info, packages)

def create_structured_commit(commit_info: Dict[str, Any], packages: List[Dict[str, Any]]) -> str:
    """Create a structured commit message for complex changes."""
    description = commit_info['description']
    type_pattern = r'^(feat|fix|docs|style|refactor|test|chore|build|ci|perf|revert)(\([^)]+\))?:\s*'
    if re.match(type_pattern, description):
        description = re.sub(type_pattern, '', description)

    # Start with the commit title
    if commit_info.get('scope'):
        message_parts = [f"{commit_info['type']}({commit_info['scope']}): {description}"]
    else:
        message_parts = [f"{commit_info['type']}: {description}"]
    
    # Add a blank line after title
    message_parts.append("")
    
    # Add detailed description if available
    if description := commit_info.get("detailed_description"):
        message_parts.append(description)
        message_parts.append("")
    
    # For multiple packages, add affected packages section
    if len(packages) > 1:
        message_parts.append("Affected packages:")
        for pkg in packages:
            message_parts.append(f"- {pkg['name']}")
            # Add files changed under each package (grouped by type for readability)
            files_by_type = group_files_by_type(pkg["files"])
            for file_type, files in files_by_type.items():
                if files:
                    message_parts.append(f"  {file_type}:")
                    for file in files[:3]:  # Limit to 3 files per type
                        message_parts.append(f"    • {file}")
                    if len(files) > 3:
                        message_parts.append(f"    • ...and {len(files) - 3} more")
        message_parts.append("")
    
    return "\n".join(message_parts)

def get_package_json_name(package_path: Path) -> Optional[str]:
    """Get package name from package.json if it exists."""
    try:
        pkg_json_path = Path.cwd() / package_path / "package.json"
        if pkg_json_path.exists():
            return json.loads(pkg_json_path.read_text()).get("name")
    except:
        return None
    return None

def is_monorepo() -> bool:
    """Detect if the current repository is a monorepo."""
    try:
        git_root = Path(check_output(["git", "rev-parse", "--show-toplevel"], text=True).strip())
        
        # Common monorepo indicators
        monorepo_indicators = [
            git_root / "packages",
            git_root / "apps",
            git_root / "libs",
            git_root / "services"
        ]
        
        # Check for package.json with workspaces
        package_json = git_root / "package.json"
        if package_json.exists():
            try:
                data = json.loads(package_json.read_text())
                if "workspaces" in data:
                    return True
            except json.JSONDecodeError:
                pass
        
        # Check for common monorepo directories
        return any(indicator.is_dir() for indicator in monorepo_indicators)
        
    except Exception as e:
        if Config().get("debug"):
            print(f"Error detecting repository type: {e}")
        return False

def get_changed_packages() -> List[Dict]:
    """Get all packages with changes in the current commit."""
    try:
        git_root = Path(check_output(["git", "rev-parse", "--show-toplevel"], text=True).strip())
        current_dir = Path.cwd()
        
        try:
            rel_path = current_dir.relative_to(git_root)
        except ValueError:
            rel_path = Path("")
        
        changed_files = check_output(["git", "diff", "--cached", "--name-only"], text=True)
        changed_files = [f for f in changed_files.strip().split("\n") if f]
        
        if Config().get("debug"):
            print("\n📦 Git root:", git_root)
            print("📦 Current dir:", current_dir)
            print("📦 Relative path:", rel_path)
            print("\n📦 Staged files detected:")
            for f in changed_files:
                print(f"  - {f}")
    except Exception as e:
        if Config().get("debug"):
            print(f"Error getting changed files: {e}")
        return []

    is_mono = is_monorepo()
    packages = {}
    
    for file in changed_files:
        if not file:
            continue

        if is_mono and file.startswith("packages/"):
            parts = file.split("/")
            if len(parts) > 1:
                pkg_path = f"packages/{parts[1]}"
                if pkg_path not in packages:
                    packages[pkg_path] = []
                packages[pkg_path].append(file)
        else:
            # For standard repos, group by directory type
            path_parts = Path(file).parts
            if not path_parts:
                continue
                
            # Determine appropriate grouping based on file type/location
            if path_parts[0] in {"src", "test", "docs", "scripts"}:
                group = path_parts[0]
            else:
                group = "root"
                
            if group not in packages:
                packages[group] = []
            packages[group].append(file)

    results = []
    for pkg_path, files in packages.items():
        if is_mono:
            if pkg_path == "root":
                scope = name = "root"
            else:
                pkg_name = get_package_json_name(Path(pkg_path))
                if pkg_name:
                    name = pkg_name
                    scope = pkg_name.split("/")[-1]
                else:
                    name = scope = pkg_path.split("/")[-1]
        else:
            # For standard repos, scope is optional
            name = pkg_path
            scope = None if pkg_path == "root" else pkg_path

        results.append({
            "name": name,
            "scope": scope,
            "files": files,
        })

    return results

def get_main_package(packages: List[Dict]) -> Optional[Dict]:
    """Get the package with the most changes."""
    if not packages:
        return {"name": "default", "scope": "default", "files": []}

    # Sort packages by number of files changed
    sorted_packages = sorted(packages, key=lambda x: len(x["files"]), reverse=True)
    return sorted_packages[0]

def prompt_user(question: str) -> bool:
    """Prompt user for yes/no question using /dev/tty."""
    try:
        with open("/dev/tty", "r", encoding="utf-8") as tty:
            print(f"{question} [Y/n]", end=" ", flush=True)
            response = tty.readline().strip().lower()
            return response == "" or response != "n"
    except Exception as e:
        print(f"Warning: Could not get user input: {str(e)}")
        return True

def display_suggestions(suggestions: List[Dict[str, str]]) -> Optional[str]:
    """Display suggestions and get user choice."""
    print("\n✨ AI Suggestions:")

    for i, suggestion in enumerate(suggestions, 1):
        print(f"\n{i}. {'=' * 48}")
        print(f"Message: {suggestion['message']}")
        print(f"Type: {suggestion['type']}")
        print(f"Scope: {suggestion['scope']}")
        print(f"Explanation: {suggestion['explanation']}")
        print("=" * 50)

    try:
        with open("/dev/tty", "r", encoding="utf-8") as tty:
            while True:
                print("\nChoose suggestion (1-3) or press Enter to skip: ", end="", flush=True)
                choice = tty.readline().strip()
                if not choice:
                    return None
                if choice in ("1", "2", "3"):
                    return suggestions[int(choice) - 1]["message"]
                print("Please enter 1, 2, 3 or press Enter to skip")
    except EOFError:
        print("\n⚠️  Input not available. Defaulting to first suggestion.")
        return suggestions[0]["message"] if suggestions else None

def analyze_commit_cohesion(packages: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Analyze if files in the commit are cohesive or should be split."""
    analysis = {
        "should_split": False,
        "reasons": [],
        "primary_scope": None,
        "files_to_unstage": []
    }
    
    if len(packages) <= 1:
        return analysis
        
    # Find the primary package (one with most changes)
    primary_package = max(packages, key=lambda x: len(x["files"]))
    analysis["primary_scope"] = primary_package["scope"]
    
    # Check for files in different scopes
    for pkg in packages:
        if pkg["scope"] != primary_package["scope"]:
            analysis["should_split"] = True
            analysis["files_to_unstage"].extend(pkg["files"])
            analysis["reasons"].append(
                f"Found {len(pkg['files'])} files in '{pkg['scope']}' scope while primary scope is '{primary_package['scope']}'"
            )
    
    return analysis

def display_cohesion_warning(analysis: Dict[str, Any]) -> bool:
    """Display warning about commit cohesion and get user decision."""
    try:
        # Get git root to convert to absolute paths
        git_root = Path(check_output(["git", "rev-parse", "--show-toplevel"], text=True).strip())
        
        # Convert to absolute paths
        files_to_unstage = [
            str(git_root / file)
            for file in analysis.get("files_to_unstage", [])
        ]
    except Exception as e:
        if Config().get("debug"):
            print(f"Error converting to absolute paths: {e}")
        files_to_unstage = analysis.get("files_to_unstage", [])

    print("\n⚠️  Potential non-cohesive commit detected!")
    print(f"\nPrimary scope: {analysis['primary_scope']}")
    print("\nReasons:")
    for reason in analysis["reasons"]:
        print(f"- {reason}")
        
    print("\nFiles that should be in separate commits:")
    # Show relative paths in the display for readability
    for file in analysis.get("files_to_unstage", []):
        print(f"  - {file}")
            
    if not prompt_user("\nWould you like to clean up this commit?"):
        return True

    # Generate unstage command with absolute paths
    unstage_cmd = "git reset HEAD " + " ".join(f'"{f}"' for f in files_to_unstage)
    
    # Try to copy to clipboard
    copied = try_copy_to_clipboard(unstage_cmd)
    
    print("\n❌ Commit aborted. To fix:")
    if copied:
        print("1. Command to unstage unrelated files has been copied to your clipboard:")
        print(f"   {unstage_cmd}")
        print("2. Paste and run the command")
    else:
        print("1. Run this command to unstage unrelated files:")
        print(f"   {unstage_cmd}")
    print("3. Run 'git commit' again to create a clean commit")
    
    return False

def try_copy_to_clipboard(text: str) -> bool:
    """Try to copy text to clipboard using various methods."""
    try:
        # Try pyperclip first if available
        try:
            import pyperclip
            pyperclip.copy(text)
            return True
        except ImportError:
            pass

        # Try pbcopy on macOS
        if sys.platform == "darwin":
            process = subprocess.Popen(['pbcopy'], stdin=subprocess.PIPE)
            process.communicate(text.encode('utf-8'))
            return True
            
        # Try xclip on Linux
        elif sys.platform.startswith('linux'):
            process = subprocess.Popen(['xclip', '-selection', 'clipboard'], stdin=subprocess.PIPE)
            process.communicate(text.encode('utf-8'))
            return True
            
        return False
    except:
        return False

def detect_secrets(diff_content: str) -> List[Dict[str, Any]]:
    """Detect potential secrets in the git diff content."""
    findings = []
    
    # Secret patterns
    secret_patterns = {
        # Cloud Provider Keys
        "AWS Key": r"AKIA[0-9A-Z]{16}",
        "AWS Secret": r"(?i)aws[_\-\s]*(?:secret|key|token|password)",
        "Google API Key": r"AIza[0-9A-Za-z\-_]{35}",
        "Google OAuth": r"[0-9]+-[0-9A-Za-z_]{32}\.apps\.googleusercontent\.com",
        "Azure Key": r"[0-9A-Fa-f]{8}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{12}",
        
        # ... [rest of the secret patterns remain the same] ...
    }
    
    for name, pattern in secret_patterns.items():
        matches = re.finditer(pattern, diff_content)
        for match in matches:
            line_number = diff_content[:match.start()].count('\n') + 1
            lines = diff_content.split('\n')
            line_content = lines[line_number - 1] if line_number <= len(lines) else ""
            masked_content = line_content.replace(match.group(), '*' * len(match.group()))
            
            findings.append({
                "type": name,
                "line": line_number,
                "content": masked_content,
                "match": '*' * len(match.group())
            })
    
    return findings

def get_new_files() -> List[str]:
    """Get list of newly added files in the staging area."""
    try:
        # Get list of new files that are staged
        result = subprocess.run(
            ["git", "diff", "--cached", "--name-status"],
            capture_output=True,
            text=True
        )
        
        new_files = []
        for line in result.stdout.splitlines():
            # 'A' indicates a newly added file
            if line.startswith('A'):
                new_files.append(line.split()[-1])
        
        return new_files
    except Exception as e:
        if Config().get("debug"):
            print(f"\n⚠️  Error getting new files: {str(e)}")
        return []

def detect_problematic_files(new_files: List[str]) -> List[Dict[str, Any]]:
    """Detect potentially problematic files among newly added files."""
    findings = []
    
    file_patterns = {
        "Environment Files": [
            r"\.env.*",
            r"config\.json",
            r"secrets\.yaml",
            r"credentials\.json",
        ],
        "Key Files": [
            r".*\.pem$",
            r".*\.key$",
            r".*\.keystore$",
            r".*\.p12$",
            r".*\.pfx$",
            r".*\.crt$",
            r".*\.cer$",
            r".*\.der$",
            r"id_rsa",
            r"id_dsa",
            r"id_ecdsa",
            r"id_ed25519",
        ],
        "Log Files": [
            r".*\.log$",
            r"npm-debug\.log.*",
            r"yarn-debug\.log.*",
            r"yarn-error\.log.*",
        ],
        "Database Files": [
            r".*\.sqlite$",
            r".*\.sqlite3$",
            r".*\.db$",
            r"dump\.sql$",
            r"database\.sql$",
        ],
        "Cache & Build Files": [
            r"\.DS_Store$",
            r"Thumbs\.db$",
            r"\.idea/",
            r"\.vscode/",
            r"node_modules/",
            r"\.next/",
            r"dist/",
            r"build/",
            r"coverage/",
        ],
    }
    
    for file in new_files:
        for category, patterns in file_patterns.items():
            for pattern in patterns:
                if re.search(pattern, file, re.IGNORECASE):
                    findings.append({
                        "type": category,
                        "file": file,
                        "pattern": pattern
                    })
                    break  # Stop after first match for this file
            
    return findings

def display_security_warnings(secret_findings: List[Dict[str, Any]], file_findings: List[Dict[str, Any]]) -> bool:
    """Display warnings about detected secrets and problematic files."""
    if not (secret_findings or file_findings):
        return True
        
    print("\n🚨 SECURITY CHECK RESULTS")
    
    # Collect all files that need to be unstaged
    files_to_unstage = []
    
    # Display secret findings
    if secret_findings:
        print("\n📛 CRITICAL: Potential sensitive data detected:")
        affected_files = set()
        
        for finding in secret_findings:
            print(f"\n⚠️  {finding['type']} detected on line {finding['line']}:")
            print(f"   {finding['content']}")
            if 'file' in finding:
                affected_files.add(finding['file'])
        
        files_to_unstage.extend(affected_files)
        
        print("\n🛡️  Security Recommendations for Secrets:")
        print("   • Review the detected patterns for false positives")
        print("   • Use environment variables for secrets")
        print("   • Consider using a secret manager")
        print("   • Update any exposed secrets immediately")
        
        if not prompt_user("\n⚠️  Detected potential secrets. Are you sure you want to commit these changes?"):
            # Generate unstage command
            unstage_cmd = "git reset HEAD " + " ".join(f'"{f}"' for f in files_to_unstage)
            
            # Try to copy to clipboard
            copied = try_copy_to_clipboard(unstage_cmd)
            
            print("\n❌ Commit aborted. To fix:")
            if copied:
                print("1. Command to unstage sensitive files has been copied to your clipboard:")
                print(f"   {unstage_cmd}")
                print("2. Paste and run the command")
            else:
                print("1. Run this command to unstage sensitive files:")
                print(f"   {unstage_cmd}")
            print("3. Review and fix the security concerns")
            print("4. Run 'git commit' again to create a clean commit")
            
            sys.exit(1)
    
    # Display problematic file findings
    if file_findings:
        print("\n📁 WARNING: Potentially problematic new files detected:")
        by_category: Dict[str, List[str]] = {}
        for finding in file_findings:
            if finding["type"] not in by_category:
                by_category[finding["type"]] = []
            by_category[finding["type"]].append(finding["file"])
            files_to_unstage.append(finding["file"])
        
        for category, files in by_category.items():
            print(f"\n⚠️  {category}:")
            for file in files:
                print(f"   • {file}")
        
        print("\n📋 Recommendations for Files:")
        print("   • Consider adding sensitive files to .gitignore")
        print("   • Use example files for templates (e.g., .env.example)")
        print("   • Consider using git-crypt for encrypted files")
        
        if not prompt_user("\n⚠️  Detected potentially sensitive files. Do you want to proceed with committing these files?"):
            # Generate unstage command
            unstage_cmd = "git reset HEAD " + " ".join(f'"{f}"' for f in files_to_unstage)
            
            # Try to copy to clipboard
            copied = try_copy_to_clipboard(unstage_cmd)
            
            print("\n❌ Commit aborted. To fix:")
            if copied:
                print("1. Command to unstage sensitive files has been copied to your clipboard:")
                print(f"   {unstage_cmd}")
                print("2. Paste and run the command")
            else:
                print("1. Run this command to unstage sensitive files:")
                print(f"   {unstage_cmd}")
            print("3. Add sensitive files to .gitignore if needed")
            print("4. Run 'git commit' again to create a clean commit")
            
            sys.exit(1)
    
    return True

def is_temporary_commit() -> bool:
    """Detect if this is a temporary/automated commit."""
    try:
        # Get the commit message
        commit_msg_file = sys.argv[1]
        with open(commit_msg_file, "r", encoding="utf-8") as f:
            msg = f.read().strip()

        # Common patterns for temporary/automated commits
        temp_patterns = [
            r'^\s*lint-staged\s+pre-commit\s+[a-f0-9]+',  # lint-staged temp commits
            r'^\s*pre-commit\s+[a-f0-9]+',                # husky/pre-commit temp commits
            r'^\s*\[automated\]',                         # generic automated commits
            r'^\s*WIP\s+on\s+',                          # git stash temp commits
            r'^\s*index\s+on\s+',                        # git stash temp commits
        ]
        
        # Check message against patterns
        if any(re.match(pattern, msg, re.IGNORECASE) for pattern in temp_patterns):
            debug_log(f"Detected temporary commit: {msg}", "Skip Check")
            return True

        # Check for common environment indicators
        env_indicators = [
            'HUSKY_GIT_PARAMS',
            'LINT_STAGED_COMMIT',
            'PRE_COMMIT_HOOK',
            'AUTOMATED_COMMIT'
        ]
        if any(os.environ.get(env) for env in env_indicators):
            debug_log("Detected automated commit environment", "Skip Check")
            return True

        # Check git environment
        git_env = check_output(['git', 'var', '-l'], text=True).lower()
        if 'gc.auto' in git_env or 'rebase.interactive' in git_env:
            debug_log("Detected git automated operation", "Skip Check")
            return True

        return False
    except Exception as e:
        if Config().get("debug"):
            print(f"\n⚠️  Error checking temporary commit: {str(e)}")
        return False

def main() -> None:
    """Main function to process git commit messages."""
    try:
        # Skip for temporary/automated commits
        if is_temporary_commit():
            sys.exit(0)

        config = Config()
        
        commit_msg_file = sys.argv[1]
        with open(commit_msg_file, "r", encoding="utf-8") as f:
            original_msg = f.read().strip()

        if original_msg.startswith("Merge"):
            sys.exit(0)

        packages = get_changed_packages()
        if not packages:
            sys.exit(0)

        print("\n🔍 Analyzing changes...")
        
        # Security checks
        try:
            # Check for secrets in all changes
            diff_content = check_output(["git", "diff", "--cached"]).decode("utf-8")
            secret_findings = detect_secrets(diff_content)
            
            # Check for problematic files (only in newly added files)
            new_files = get_new_files()
            file_findings = detect_problematic_files(new_files)
            
            if secret_findings or file_findings:
                if not display_security_warnings(secret_findings, file_findings):
                    print("\n❌ Commit aborted. Please address the security concerns before committing.")
                    sys.exit(1)
        except Exception as e:
            if config.get("debug"):
                print(f"\n⚠️  Error during security checks: {str(e)}")

        # Only proceed with AI and other checks if cohesion check passes
        if config.get("use_ai", True):
            prompt = enhance_ai_prompt(packages, original_msg)
            token_count = count_tokens(prompt)
            debug_log(
                get_token_cost(token_count),
                "Token Usage 💰"
            )
            
            if prompt_user("\nWould you like AI suggestions?"):
                print("\n🤖 Getting AI suggestions...")
                suggestions = get_ai_suggestion(prompt, original_msg)
                if suggestions:
                    chosen_message = display_suggestions(suggestions)
                    if chosen_message:
                        with open(commit_msg_file, "w", encoding="utf-8") as f:
                            f.write(chosen_message)
                        print("✅ Commit message updated!\n")
                        return

        # Fallback to automatic formatting
        print("\n⚙️ Using automatic formatting...")
        commit_info = {
            "type": "feat",  # Default type
            "scope": get_main_package(packages)["scope"],
            "description": original_msg
        }
        new_msg = create_commit_message(commit_info, packages)
        
        print(f"\n✨ Suggested message:\n{new_msg}")

        if prompt_user("\nUse suggested message?"):
            with open(commit_msg_file, "w", encoding="utf-8") as f:
                f.write(new_msg)
            print("✅ Commit message updated!\n")

    except Exception as e:
        print(f"❌ Error: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()
